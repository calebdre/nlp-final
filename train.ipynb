{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import Pipeline\n",
    "from lang_pair import LangPair\n",
    "\n",
    "from models.encoder import Encoder\n",
    "from models.decoder import Decoder\n",
    "from models.attn import Attn\n",
    "\n",
    "from coach import Coach\n",
    "from translator import Translator\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vi_vi_vocab, vi_en_vocab = Pipeline.load(\"vi_vi_train\").data, Pipeline.load(\"vi_en_train\").data\n",
    "# vi_en_pair = LangPair(vi_vi_vocab, vi_en_vocab, device = device)\n",
    "# with open(\"transforms/vi_en_lang_pair.pkl\", \"wb+\") as f:\n",
    "#     torch.save(vi_en_pair, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transforms/vi_en_lang_pair.pkl\", \"rb+\") as f:\n",
    "    lang_pair = torch.load(f)\n",
    "with open(\"vi_en_validation_lang_pair.pkl\", \"rb+\") as f:\n",
    "    valid_lang_pair = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "batch_size = 20\n",
    "learning_rate = .1\n",
    "embed_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_params = {\n",
    "    \"input_vocab_size\": lang_pair.lang1_vocab.size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"n_layers\": 1,\n",
    "    \"dropout\": 0,\n",
    "    \"embed_size\": embed_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_params = {\n",
    "    \"target_vocab_size\": lang_pair.lang2_vocab.size,\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"n_layers\": 1,\n",
    "    \"dropout\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_params = {\n",
    "    \"hidden_size\": hidden_size,\n",
    "    \"method\": \"dot\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Attn(**attn_params).to(device)\n",
    "encoder = Encoder(**enc_params).to(device)\n",
    "decoder = Decoder(**dec_params, attn = attn).to(device)\n",
    "decoder_attn = Decoder(**dec_params, attn = attn).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_optimizer = optim.SGD(encoder.parameters(), lr = learning_rate)\n",
    "dec_optimizer = optim.SGD(decoder.parameters(), lr = learning_rate)\n",
    "dec_attn_optimizer = optim.SGD(decoder_attn.parameters(), lr = learning_rate)\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coach_params = {\n",
    "    \"lang_pair\": lang_pair, \n",
    "    \"encoder\": encoder, \n",
    "    \"enc_optimizer\": enc_optimizer, \n",
    "    \"decoder\": decoder, \n",
    "    \"dec_optimizer\": dec_optimizer, \n",
    "    \"loss_fn\": loss_fn,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "coach_attn_params = {\n",
    "    **coach_params,\n",
    "    \"dec_optimizer\": dec_attn_optimizer,\n",
    "    \"decoder\": decoder_attn\n",
    "}\n",
    "\n",
    "coach = Coach(**coach_params)\n",
    "coach_attn = Coach(**coach_attn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_training_params = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"iterations\": 10000,\n",
    "    \"print_interval\": 1000,\n",
    "    \"batch_size\": batch_size\n",
    "}\n",
    "\n",
    "epoch_training_params = {\n",
    "    \"num_epochs\": 2,\n",
    "    \"print_interval\": 5000,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"percent_of_data\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching batches...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  10%|█         | 51/500 [02:17<21:48,  2.91s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (1/10) average loss: -3.1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  20%|██        | 101/500 [04:27<17:39,  2.66s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (2/10) average loss: -9.1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  30%|███       | 151/500 [06:08<10:26,  1.79s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (3/10) average loss: -16.2682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  40%|████      | 201/500 [08:00<14:49,  2.97s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (4/10) average loss: -22.9321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  50%|█████     | 251/500 [09:49<10:01,  2.41s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (5/10) average loss: -28.3475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  60%|██████    | 301/500 [11:17<07:32,  2.27s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (6/10) average loss: -35.8933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  70%|███████   | 351/500 [13:26<07:12,  2.90s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (7/10) average loss: -41.3195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  80%|████████  | 401/500 [15:44<04:54,  2.98s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (8/10) average loss: -49.2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  90%|█████████ | 451/500 [17:36<02:23,  2.94s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (9/10) average loss: -58.2209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations: 100%|██████████| 500/500 [19:38<00:00,  1.95s/ batch]\n"
     ]
    }
   ],
   "source": [
    "# losses = coach.train_random(**rand_training_params)\n",
    "losses = coach.train_random(**rand_training_params)\n",
    "with open(\"model_test.pkl\", \"wb\") as f:\n",
    "    torch.save(coach, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching batches...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  10%|█         | 51/500 [01:46<17:30,  2.34s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (1/10) average loss: -3.2547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  20%|██        | 101/500 [03:55<26:40,  4.01s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (2/10) average loss: -9.0167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  30%|███       | 151/500 [06:23<15:21,  2.64s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (3/10) average loss: -14.8629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  40%|████      | 201/500 [07:58<09:26,  1.89s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (4/10) average loss: -23.3650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  50%|█████     | 251/500 [10:01<06:56,  1.67s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (5/10) average loss: -28.8463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  60%|██████    | 301/500 [11:44<05:45,  1.74s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (6/10) average loss: -36.5873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  70%|███████   | 351/500 [13:32<06:57,  2.80s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (7/10) average loss: -39.3202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  80%|████████  | 401/500 [15:37<05:01,  3.04s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (8/10) average loss: -45.5428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  90%|█████████ | 451/500 [17:41<01:11,  1.46s/ batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval (9/10) average loss: -53.7073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations: 100%|██████████| 500/500 [19:14<00:00,  1.31s/ batch]\n"
     ]
    }
   ],
   "source": [
    "# losses = coach.train_random(**rand_training_params)\n",
    "attn_losses, attns = coach_attn.train_random(**rand_training_params)\n",
    "with open(\"model_attn_test.pkl\", \"wb\") as f:\n",
    "    torch.save(coach_attn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
